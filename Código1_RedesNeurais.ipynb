{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Redes Neurais - Implementação de MLP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giovanna Zolin Pinheiro Hayasida nº USP 9762848\n",
    "### Luna Wagner Cunha nº USP 9762831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importando pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      256  257  258  259  260  261  262  263  264  265\n",
      "0       1    0    0    0    0    0    0    0    0    0\n",
      "1       1    0    0    0    0    0    0    0    0    0\n",
      "2       1    0    0    0    0    0    0    0    0    0\n",
      "3       1    0    0    0    0    0    0    0    0    0\n",
      "4       1    0    0    0    0    0    0    0    0    0\n",
      "5       1    0    0    0    0    0    0    0    0    0\n",
      "6       1    0    0    0    0    0    0    0    0    0\n",
      "7       1    0    0    0    0    0    0    0    0    0\n",
      "8       1    0    0    0    0    0    0    0    0    0\n",
      "9       1    0    0    0    0    0    0    0    0    0\n",
      "10      1    0    0    0    0    0    0    0    0    0\n",
      "11      1    0    0    0    0    0    0    0    0    0\n",
      "12      1    0    0    0    0    0    0    0    0    0\n",
      "13      1    0    0    0    0    0    0    0    0    0\n",
      "14      1    0    0    0    0    0    0    0    0    0\n",
      "15      1    0    0    0    0    0    0    0    0    0\n",
      "16      1    0    0    0    0    0    0    0    0    0\n",
      "17      1    0    0    0    0    0    0    0    0    0\n",
      "18      1    0    0    0    0    0    0    0    0    0\n",
      "19      1    0    0    0    0    0    0    0    0    0\n",
      "20      0    1    0    0    0    0    0    0    0    0\n",
      "21      0    1    0    0    0    0    0    0    0    0\n",
      "22      0    1    0    0    0    0    0    0    0    0\n",
      "23      0    1    0    0    0    0    0    0    0    0\n",
      "24      0    1    0    0    0    0    0    0    0    0\n",
      "25      0    1    0    0    0    0    0    0    0    0\n",
      "26      0    1    0    0    0    0    0    0    0    0\n",
      "27      0    1    0    0    0    0    0    0    0    0\n",
      "28      0    1    0    0    0    0    0    0    0    0\n",
      "29      0    1    0    0    0    0    0    0    0    0\n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "1563    0    0    0    0    0    0    0    0    0    1\n",
      "1564    0    0    0    0    0    0    0    0    0    1\n",
      "1565    0    0    0    0    0    0    0    0    0    1\n",
      "1566    0    0    0    0    0    0    0    0    0    1\n",
      "1567    0    0    0    0    0    0    0    0    0    1\n",
      "1568    0    0    0    0    0    0    0    0    0    1\n",
      "1569    0    0    0    0    0    0    0    0    0    1\n",
      "1570    0    0    0    0    0    0    0    0    0    1\n",
      "1571    0    0    0    0    0    0    0    0    0    1\n",
      "1572    0    0    0    0    0    0    0    0    0    1\n",
      "1573    0    0    0    0    0    0    0    0    0    1\n",
      "1574    0    0    0    0    0    0    0    0    0    1\n",
      "1575    0    0    0    0    0    0    0    0    0    1\n",
      "1576    0    0    0    0    0    0    0    0    0    1\n",
      "1577    0    0    0    0    0    0    0    0    0    1\n",
      "1578    0    0    0    0    0    0    0    0    0    1\n",
      "1579    0    0    0    0    0    0    0    0    0    1\n",
      "1580    0    0    0    0    0    0    0    0    0    1\n",
      "1581    0    0    0    0    0    0    0    0    0    1\n",
      "1582    0    0    0    0    0    0    0    0    0    1\n",
      "1583    0    0    0    0    0    0    0    0    0    1\n",
      "1584    0    0    0    0    0    0    0    0    0    1\n",
      "1585    0    0    0    0    0    0    0    0    0    1\n",
      "1586    0    0    0    0    0    0    0    0    0    1\n",
      "1587    0    0    0    0    0    0    0    0    0    1\n",
      "1588    0    0    0    0    0    0    0    0    0    1\n",
      "1589    0    0    0    0    0    0    0    0    0    1\n",
      "1590    0    0    0    0    0    0    0    0    0    1\n",
      "1591    0    0    0    0    0    0    0    0    0    1\n",
      "1592    0    0    0    0    0    0    0    0    0    1\n",
      "\n",
      "[1593 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "## Olhando o banco de dados\n",
    "data = pd.read_csv('semeion.csv', delimiter = \" \", header = None)\n",
    "print(data.iloc[:, -11:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   246  247  248  249  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0 ...   1.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   1.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   250  251  252  253  254  255  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Particionando as covariáveis\n",
    "X = data.drop(data.columns[[-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]],axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   256  257  258  259  260  261  262  263  264  265\n",
       "0    1    0    0    0    0    0    0    0    0    0\n",
       "1    1    0    0    0    0    0    0    0    0    0\n",
       "2    1    0    0    0    0    0    0    0    0    0\n",
       "3    1    0    0    0    0    0    0    0    0    0\n",
       "4    1    0    0    0    0    0    0    0    0    0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Particionando a resposta\n",
    "Y = data.drop(data.columns [[range(0,256)]], axis= 1)\n",
    "Y = Y.drop(Y.columns [[-1]], axis= 1)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função da MLP\n",
    "class MLP(object):\n",
    "    # Dicionário do python para armazenar o modelo da MLP\n",
    "\tmod = {}\n",
    "\tdE2_dw_h_b = 0\n",
    "\tdE2_dw_o_b = 0\n",
    "    # Construtor da classe\n",
    "\tdef __init__(self):\n",
    "\t\t# Iniciando MLP\n",
    "\t\treturn\n",
    "    # Função de Ativação dos neuronios da MLP\n",
    "\tdef fneu(net):\n",
    "\t\treturn (1 / (1 + np.exp(-net)))\n",
    "\n",
    "    # Função para calcular a derivada\n",
    "\tdef df_dnet(f_net):\n",
    "\t\treturn (f_net * (1 - f_net))\n",
    "\n",
    "    # Função que inicializa a arquitetura da MLP baseado no problema especifico\n",
    "\tdef arch(self,input_lenght=256,hidden_lenght=20,output_lenght=10,fneu=fneu,df_dnet=df_dnet):\n",
    "\t\tself.mod['input_lenght'] = input_lenght\n",
    "\t\tself.mod['hidden_lenght'] = hidden_lenght\n",
    "\t\tself.mod['output_lenght'] = output_lenght\n",
    "\t\tself.mod['hidden_layer'] = np.random.uniform(-0.5,+0.5,(hidden_lenght,input_lenght+1))\n",
    "\t\tself.mod['output_layer'] = np.random.uniform(-0.5,+0.5,(output_lenght,hidden_lenght+1))\n",
    "\t\tself.mod['fneu'] = fneu\n",
    "\t\tself.mod['df_dnet'] = df_dnet\n",
    "        # Realiza o forward do algoritmo, onde calcula o output final a partir dos pesos atuais\n",
    "\tdef forward(self, X):\n",
    "\t\t#Retirando os valores do modelo\n",
    "\t\thidden = self.mod['hidden_layer'] \n",
    "\t\toutput = self.mod['output_layer']\n",
    "\t\t#Adicionando o 1 para a multiplicação\n",
    "\t\tX = np.concatenate((X,np.array([1])))\n",
    "\n",
    "\n",
    "\t\t\n",
    "\t\t#CAMADA ESCONDIDA\n",
    "\t\tnet_h = np.matmul(hidden,X)\n",
    "\t\tf_net_h = self.mod['fneu'](net_h)\n",
    "\t\tdf_net_h = self.mod['df_dnet'](f_net_h)\n",
    "\t\t\n",
    "\t\t#CAMADA SAÍDA\n",
    "\t\tf_net_h_c = np.concatenate((f_net_h,np.array([1])))\n",
    "\t\tnet_o = np.matmul(output,f_net_h_c)\n",
    "\t\tf_net_o = self.mod['fneu'](net_o)\n",
    "\t\tdf_net_o = self.mod['df_dnet'](f_net_o)\n",
    "        \n",
    "\t\treturn{\n",
    "\t\t\t\"f_net_h\": f_net_h,\n",
    "\t\t\t\"df_net_h\":df_net_h,\n",
    "\t\t\t\"f_net_o\": f_net_o,\n",
    "\t\t\t\"df_net_o\":df_net_o\n",
    "\t\t}\n",
    "\n",
    "    # Realiza o treinamento da rede utilizando backpropagation com regra delta\n",
    "\tdef backpropagation(self,X,Y,eta=0.5,alpha=0.5,max_error=0.000001,max_iter=500):\n",
    "\t\tcounter = 0\n",
    "\t\ttotal_error = 2*max_error\n",
    "\n",
    "\t\t# Treinamento ocorre enquanto o erro for maior que o aceitável ou o número maximo de iterações não tiver sido atingido\n",
    "\t\twhile total_error > max_error and counter < max_iter:\n",
    "\t\t\ttotal_error = 0\n",
    "\n",
    "\t\t\tfor i in range(0,X.shape[0]):\n",
    "\t\t\t\tx_i = X[i,:]\n",
    "\t\t\t\ty_i = Y[i]\n",
    "\n",
    "\t\t\t\t#forward\n",
    "\t\t\t\tfw = self.forward(x_i)\n",
    "\n",
    "\t\t\t\t#erro\n",
    "\t\t\t\terror_o_k = (y_i-fw['f_net_o'])\n",
    "\t\t\t\t\n",
    "\t\t\t\ttotal_error = total_error + np.sum(error_o_k*error_o_k)\n",
    "\n",
    "\t\t\t\t#backpropagation / calculo das derivadas\n",
    "\t\t\t\tdelta_out = error_o_k*fw['df_net_o']\n",
    "\t\t\t\tdE2_dw_o = np.multiply(np.array([-2*delta_out]).T,np.concatenate((fw['f_net_h'],np.array([1]))))\n",
    "\n",
    "\t\t\t\tdelta_h = np.matmul(np.array([delta_out]),self.mod['output_layer'][:,0:self.mod['hidden_lenght']])\n",
    "\t\t\t\tdE2_dw_h = delta_h * (np.multiply(-2*fw['df_net_h'],np.array([np.concatenate((x_i,np.array([1])))]).T))\n",
    "\n",
    "\n",
    "\t\t\t\t# Atualização dos pesos\n",
    "\t\t\t\tself.mod['output_layer'] = self.mod['output_layer'] - eta*dE2_dw_o - alpha*self.dE2_dw_o_b\n",
    "\t\t\t\tif counter == 0:\n",
    "\t\t\t\t\tself.mod['hidden_layer'] = self.mod['hidden_layer'] - np.reshape(np.array([eta*dE2_dw_h]).T,(self.mod['hidden_lenght'],x_i.size+1))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.mod['hidden_layer'] = self.mod['hidden_layer'] - np.reshape(np.array([eta*dE2_dw_h]).T,(self.mod['hidden_lenght'],x_i.size+1)) - np.reshape(np.array([alpha*self.dE2_dw_h_b]).T,(self.mod['hidden_lenght'],x_i.size+1))\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\tself.dE2_dw_o_b = dE2_dw_o\n",
    "\t\t\t\tself.dE2_dw_h_b = dE2_dw_h\n",
    "\n",
    "\t\t\t# Término da iteração do treinamento\n",
    "\t\t\ttotal_error = total_error/X.shape[0]\n",
    "\t\t\tcounter = counter+1\n",
    "\t\t\tif (counter % 100) == 0:\n",
    "\t\t\t\tprint(\"Iter:\",counter,\" Error:\",total_error)\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\tdef run(self,X,Y,task,size=20,eta=0.1,alpha=0.5,max_iter=500,train_size=0.7,threshold=0.000001):\n",
    "\t\tids = random.sample(range(0,X.shape[0]),np.floor(train_size*X.shape[0]).astype(np.int))\n",
    "\t\tids_left = diff(range(0,X.shape[0]),ids)\n",
    "\t\t# Base de Treino\n",
    "\t\ttrain_set = X[ids,:]\n",
    "\t\tY=np.array(Y)\n",
    "\t\ttrain_classes = Y[ids,:]\n",
    "\n",
    "\t\t# Base de Teste\n",
    "\t\ttest_set = X[ids_left,:]\n",
    "\t\ttest_classes = Y[ids_left,:]\n",
    "\n",
    "\t\tself.arch(input_lenght=X.shape[1],hidden_lenght=size,output_lenght=Y.shape[1])\n",
    "\t\tprint('MLP criada\\nIniciando Treinamento')\n",
    "\t\tself.backpropagation(train_set,train_classes,eta=eta,alpha=alpha,max_error=threshold,max_iter=max_iter)\n",
    "\t\tprint('Rede Neural Treinada\\nIniciando Teste')\n",
    "\n",
    "\t\tcorrect = 0\n",
    "\t\tsqerror = 0\n",
    "\t\tfor i in range(0,test_set.shape[0]):\n",
    "\t\t\tx_i = test_set[i]\n",
    "\t\t\ty_i = test_classes[i]\n",
    "\n",
    "\t\t\tif task == 'C':\n",
    "\t\t\t\ty_hat_i = np.round(self.forward(x_i)['f_net_o'])\n",
    "\t\t\tif task == 'R':\n",
    "\t\t\t\ty_hat_i = self.forward(x_i)['f_net_o']\n",
    "\t\t\t\n",
    "\t\t\terror = y_i - y_hat_i\n",
    "\t\t\tif (np.sum((error)**2) == 0):\n",
    "\t\t\t\tcorrect = correct + 1\n",
    "\t\t\tsqerror = sqerror + np.sum(error*error)\n",
    "\n",
    "\t\t\tpass\n",
    "\n",
    "\t\tprint('Rede Neural Testada')\n",
    "\t\taccuracy = correct/test_set.shape[0]\n",
    "\t\tsqerror = sqerror/test_set.shape[0]\n",
    "\t\t\n",
    "\t\treturn {\n",
    "\t\t\t\"accuracy\": accuracy,\n",
    "\t\t\t\"error\": sqerror    \n",
    "\t\t}\n",
    "\t#FIM DA MLP    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(first, second):\n",
    "        second = set(second)\n",
    "        return [item for item in first if item not in second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para aplicação nos dados\n",
    "def digit_test(X,eta=0.1,alpha=0,max_iter=500,size=20,train_size=0.7):\n",
    "    X = np.array(X)\n",
    "    X = X.astype(np.float)\n",
    "    # Normalizando X\n",
    "    for i in range(X.shape[1]):\n",
    "        X[:,i] = (X[:,i] - np.amin(X[:,i])) / (np.amax(X[:,i]) - np.amin(X[:,i]))\n",
    "    print('\\nProcessando Base de Dígitos')\n",
    "    mlp = MLP()\n",
    "    return mlp.run(X,Y,'C',eta=eta,alpha=alpha,size = size,max_iter=max_iter,train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.027392471257461908\n",
      "Iter: 200  Error: 0.019121797182233807\n",
      "Iter: 300  Error: 0.015794703837426465\n",
      "Iter: 400  Error: 0.011998403752080354\n",
      "Iter: 500  Error: 0.011389745508515656\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.0013875691696376448\n",
      "Iter: 200  Error: 0.0006001593669163447\n",
      "Iter: 300  Error: 0.00037711166152149466\n",
      "Iter: 400  Error: 0.0002729886604355169\n",
      "Iter: 500  Error: 0.00021309950189464752\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.0024644859322432936\n",
      "Iter: 200  Error: 0.0011577522027273201\n",
      "Iter: 300  Error: 0.0010571789745884544\n",
      "Iter: 400  Error: 0.0010118440194530544\n",
      "Iter: 500  Error: 0.0009861148107126205\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 1.7973094170403587\n",
      "Iter: 200  Error: 1.7973094170403587\n",
      "Iter: 300  Error: 1.7973094170403587\n",
      "Iter: 400  Error: 1.7973094170403587\n",
      "Iter: 500  Error: 1.7973094170403587\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.5419743506277288\n",
      "Iter: 200  Error: 0.30705718499616425\n",
      "Iter: 300  Error: 0.19523575549260527\n",
      "Iter: 400  Error: 0.13905680438498724\n",
      "Iter: 500  Error: 0.10640845411250537\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.0031068149244781996\n",
      "Iter: 200  Error: 0.002363641545240385\n",
      "Iter: 300  Error: 0.002151795865949453\n",
      "Iter: 400  Error: 0.0020527493629764098\n",
      "Iter: 500  Error: 0.0019958518128100956\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.005628757709081686\n",
      "Iter: 200  Error: 0.004531369412830669\n",
      "Iter: 300  Error: 0.004241805899668319\n",
      "Iter: 400  Error: 0.004109289376157961\n",
      "Iter: 500  Error: 0.004033390358047022\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.002521628944916915\n",
      "Iter: 200  Error: 0.0016290010635301464\n",
      "Iter: 300  Error: 0.0014115148903080241\n",
      "Iter: 400  Error: 0.0013111082119170669\n",
      "Iter: 500  Error: 0.001253388719561671\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "\n",
      "Processando Base de Dígitos\n",
      "MLP criada\n",
      "Iniciando Treinamento\n",
      "Iter: 100  Error: 0.0048990251162039766\n",
      "Iter: 200  Error: 0.0026732981673979095\n",
      "Iter: 300  Error: 0.002433771286227319\n",
      "Iter: 400  Error: 0.0023338515555873973\n",
      "Iter: 500  Error: 0.0022792460378105264\n",
      "Rede Neural Treinada\n",
      "Iniciando Teste\n",
      "Rede Neural Testada\n",
      "+---------------------+-----------------+---------------------------+---------------------+\n",
      "| Taxa de Aprendizado | Nº de Neurônios | Tamanho da base de treino |       Acurácia      |\n",
      "+---------------------+-----------------+---------------------------+---------------------+\n",
      "|         0.1         |        5        |            0.7            |  0.7322175732217573 |\n",
      "|         0.1         |        20       |            0.7            |  0.8493723849372385 |\n",
      "|         0.1         |       100       |            0.7            |  0.8598326359832636 |\n",
      "|         100         |        20       |            0.7            | 0.09623430962343096 |\n",
      "|        0.001        |        20       |            0.7            |  0.8096234309623431 |\n",
      "|         0.1         |        20       |            0.7            |  0.8765690376569037 |\n",
      "|         0.1         |        20       |            0.5            |  0.8193224592220828 |\n",
      "|         0.1         |        20       |            0.7            |  0.8401253918495298 |\n",
      "|         0.1         |        20       |            0.9            |         0.85        |\n",
      "+---------------------+-----------------+---------------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "print('Iniciando')\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Taxa de Aprendizado\",\"Nº de Neurônios\",\"Tamanho da base de treino\",\"Acurácia\"]\n",
    "\n",
    "# Variando quantidade de neurônios\n",
    "ret = digit_test(X,eta=0.1, size = 5)\n",
    "table.add_row([0.1,5,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,eta=0.1,size=20)\n",
    "table.add_row([0.1,20,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,eta=0.1,size = 100)\n",
    "table.add_row([0.1,100,0.7,ret['accuracy']])\n",
    "\n",
    "# Variando taxa de aprendizado\n",
    "ret = digit_test(X,eta=100)\n",
    "table.add_row([100,20,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,eta=0.001)\n",
    "table.add_row([0.001,20,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,eta=0.1)\n",
    "table.add_row([0.1,20,0.7,ret['accuracy']])\n",
    "\n",
    "# Variando tamanho da base de treino\n",
    "ret = digit_test(X,train_size=0.5)\n",
    "table.add_row([0.1,20,0.5,ret['accuracy']])\n",
    "ret = digit_test(X,train_size=0.6)\n",
    "table.add_row([0.1,20,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,train_size=0.9)\n",
    "table.add_row([0.1,20,0.9,ret['accuracy']])\n",
    "\n",
    "# Resultados\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

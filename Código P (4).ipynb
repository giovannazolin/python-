{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('semeion.csv', delimiter = \" \", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      256  257  258  259  260  261  262  263  264  265\n",
      "0       1    0    0    0    0    0    0    0    0    0\n",
      "1       1    0    0    0    0    0    0    0    0    0\n",
      "2       1    0    0    0    0    0    0    0    0    0\n",
      "3       1    0    0    0    0    0    0    0    0    0\n",
      "4       1    0    0    0    0    0    0    0    0    0\n",
      "5       1    0    0    0    0    0    0    0    0    0\n",
      "6       1    0    0    0    0    0    0    0    0    0\n",
      "7       1    0    0    0    0    0    0    0    0    0\n",
      "8       1    0    0    0    0    0    0    0    0    0\n",
      "9       1    0    0    0    0    0    0    0    0    0\n",
      "10      1    0    0    0    0    0    0    0    0    0\n",
      "11      1    0    0    0    0    0    0    0    0    0\n",
      "12      1    0    0    0    0    0    0    0    0    0\n",
      "13      1    0    0    0    0    0    0    0    0    0\n",
      "14      1    0    0    0    0    0    0    0    0    0\n",
      "15      1    0    0    0    0    0    0    0    0    0\n",
      "16      1    0    0    0    0    0    0    0    0    0\n",
      "17      1    0    0    0    0    0    0    0    0    0\n",
      "18      1    0    0    0    0    0    0    0    0    0\n",
      "19      1    0    0    0    0    0    0    0    0    0\n",
      "20      0    1    0    0    0    0    0    0    0    0\n",
      "21      0    1    0    0    0    0    0    0    0    0\n",
      "22      0    1    0    0    0    0    0    0    0    0\n",
      "23      0    1    0    0    0    0    0    0    0    0\n",
      "24      0    1    0    0    0    0    0    0    0    0\n",
      "25      0    1    0    0    0    0    0    0    0    0\n",
      "26      0    1    0    0    0    0    0    0    0    0\n",
      "27      0    1    0    0    0    0    0    0    0    0\n",
      "28      0    1    0    0    0    0    0    0    0    0\n",
      "29      0    1    0    0    0    0    0    0    0    0\n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "1563    0    0    0    0    0    0    0    0    0    1\n",
      "1564    0    0    0    0    0    0    0    0    0    1\n",
      "1565    0    0    0    0    0    0    0    0    0    1\n",
      "1566    0    0    0    0    0    0    0    0    0    1\n",
      "1567    0    0    0    0    0    0    0    0    0    1\n",
      "1568    0    0    0    0    0    0    0    0    0    1\n",
      "1569    0    0    0    0    0    0    0    0    0    1\n",
      "1570    0    0    0    0    0    0    0    0    0    1\n",
      "1571    0    0    0    0    0    0    0    0    0    1\n",
      "1572    0    0    0    0    0    0    0    0    0    1\n",
      "1573    0    0    0    0    0    0    0    0    0    1\n",
      "1574    0    0    0    0    0    0    0    0    0    1\n",
      "1575    0    0    0    0    0    0    0    0    0    1\n",
      "1576    0    0    0    0    0    0    0    0    0    1\n",
      "1577    0    0    0    0    0    0    0    0    0    1\n",
      "1578    0    0    0    0    0    0    0    0    0    1\n",
      "1579    0    0    0    0    0    0    0    0    0    1\n",
      "1580    0    0    0    0    0    0    0    0    0    1\n",
      "1581    0    0    0    0    0    0    0    0    0    1\n",
      "1582    0    0    0    0    0    0    0    0    0    1\n",
      "1583    0    0    0    0    0    0    0    0    0    1\n",
      "1584    0    0    0    0    0    0    0    0    0    1\n",
      "1585    0    0    0    0    0    0    0    0    0    1\n",
      "1586    0    0    0    0    0    0    0    0    0    1\n",
      "1587    0    0    0    0    0    0    0    0    0    1\n",
      "1588    0    0    0    0    0    0    0    0    0    1\n",
      "1589    0    0    0    0    0    0    0    0    0    1\n",
      "1590    0    0    0    0    0    0    0    0    0    1\n",
      "1591    0    0    0    0    0    0    0    0    0    1\n",
      "1592    0    0    0    0    0    0    0    0    0    1\n",
      "\n",
      "[1593 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('semeion.csv', delimiter = \" \", header = None)\n",
    "print(data.iloc[:, -11:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   246  247  248  249  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0 ...   1.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   1.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   250  251  252  253  254  255  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(data.columns[[-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]],axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Luna\\Downloads\\ANA\\lib\\site-packages\\pandas\\core\\indexes\\base.py:2095: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   256  257  258  259  260  261  262  263  264  265  266\n",
       "0    1    0    0    0    0    0    0    0    0    0  NaN\n",
       "1    1    0    0    0    0    0    0    0    0    0  NaN\n",
       "2    1    0    0    0    0    0    0    0    0    0  NaN\n",
       "3    1    0    0    0    0    0    0    0    0    0  NaN\n",
       "4    1    0    0    0    0    0    0    0    0    0  NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.drop(data.columns [[range(0,256)]], axis= 1)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   256  257  258  259  260  261  262  263  264  265\n",
       "0    1    0    0    0    0    0    0    0    0    0\n",
       "1    1    0    0    0    0    0    0    0    0    0\n",
       "2    1    0    0    0    0    0    0    0    0    0\n",
       "3    1    0    0    0    0    0    0    0    0    0\n",
       "4    1    0    0    0    0    0    0    0    0    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.drop(Y.columns [[-1]], axis= 1)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    # Dictionary do python para armazenar o modelo da MLP\n",
    "\tmodel = {}\n",
    "\tdE2_dw_h_b = 0\n",
    "\tdE2_dw_o_b = 0\n",
    "    # Construtor da classe\n",
    "\tdef __init__(self):\n",
    "\t\t# Iniatialize MLP class\n",
    "\t\t#self.architecture()\n",
    "\t\treturn\n",
    "    # Função de Ativação dos neuronios da MLP\n",
    "\tdef fnet(net):\n",
    "\t\treturn (1 / (1 + np.exp(-net)))\n",
    "\n",
    "\t# Função para calcula a derivada\n",
    "\tdef df_dnet(f_net):\n",
    "\t\treturn (f_net * (1 - f_net))\n",
    "\n",
    "\t# Função que inicializa a arquitetura da MLP baseado no problema especifico\n",
    "\tdef architecture(self,input_lenght=256,hidden_lenght=5,output_lenght=10,fnet=fnet,df_dnet=df_dnet):\n",
    "\t\tself.model['input_lenght'] = input_lenght\n",
    "\t\tself.model['hidden_lenght'] = hidden_lenght\n",
    "\t\tself.model['output_lenght'] = output_lenght\n",
    "\t\tself.model['hidden_layer'] = np.random.uniform(-0.5,+0.5,(hidden_lenght,input_lenght+1))\n",
    "\t\tself.model['output_layer'] = np.random.uniform(-0.5,+0.5,(output_lenght,hidden_lenght+1))\n",
    "\t\tself.model['fnet'] = fnet\n",
    "\t\tself.model['df_dnet'] = df_dnet\n",
    "        # Realiza o forward do algoritmo, onde calcula o output final a partir dos pesos atuais\n",
    "\tdef forward(self, X):\n",
    "\t\t#Retirando os valores do modelo\n",
    "\t\thidden = self.model['hidden_layer'] \n",
    "\t\toutput = self.model['output_layer']\n",
    "\t\t#Adicionando o 1 para a multiplicação\n",
    "\t\tX = np.concatenate((X,np.array([1])))\n",
    "\n",
    "\t\t#print('hidden=',hidden,'\\n')\n",
    "\t\t#print('output=',output,'\\n')\n",
    "\t\t\n",
    "\t\t#CAMADA ESCONDIDA\n",
    "\t\tnet_h = np.matmul(hidden,X)\n",
    "\t\t#print('net_h=',net_h,'\\n')\n",
    "\t\tf_net_h = self.model['fnet'](net_h)\n",
    "\t\t#print('f_net_h=',f_net_h,'\\n')\n",
    "\t\tdf_net_h = self.model['df_dnet'](f_net_h)\n",
    "\t\t#f_net_h = np.rint(f_net_h)\n",
    "\t\t\n",
    "\t\t#CAMADA SAÍDA\n",
    "\t\tf_net_h_c = np.concatenate((f_net_h,np.array([1])))\n",
    "\t\tnet_o = np.matmul(output,f_net_h_c)\n",
    "\t\t#print('net_o=',net_o,'\\n')\n",
    "\t\t#print('net_o=',net_o,'\\n')\n",
    "\t\tf_net_o = self.model['fnet'](net_o)\n",
    "\t\t#print('f_net_o=',f_net_o,'\\n')\n",
    "\t\tdf_net_o = self.model['df_dnet'](f_net_o)\n",
    "\t\t#f_net_o = np.rint(f_net_o)\n",
    "\n",
    "\t\treturn{\n",
    "\t\t\t\"f_net_h\": f_net_h,\n",
    "\t\t\t\"df_net_h\":df_net_h,\n",
    "\t\t\t\"f_net_o\": f_net_o,\n",
    "\t\t\t\"df_net_o\":df_net_o\n",
    "\t\t}\n",
    "    # Realiza o treinamento da rede utilizando backpropagation com regra delta\n",
    "\tdef backpropagation(self,X,Y,eta=0.5,alpha=0.5,max_error=0.000001,max_iter=500):\n",
    "\t\tcounter = 0\n",
    "\t\ttotal_error = 2*max_error\n",
    "\n",
    "\t\t# Treinamento ocorre enquanto o erro for maior que o aceitavel ou o numero maximo de iterações nao tiver sido atingido\n",
    "\t\twhile total_error > max_error and counter < max_iter:\n",
    "\t\t\ttotal_error = 0\n",
    "\n",
    "\t\t\tfor i in range(0,X.shape[0]):\n",
    "\t\t\t\tx_i = X[i,:]\n",
    "\t\t\t\ty_i = Y[i]\n",
    "\t\t\t\t#print('x_i=',x_i,'\\n')\n",
    "\t\t\t\t#print('y_i=',y_i,'\\n')\n",
    "\n",
    "\t\t\t\t#forward\n",
    "\t\t\t\tfw = self.forward(x_i)\n",
    "\n",
    "\t\t\t\t#erro\n",
    "\t\t\t\terror_o_k = (y_i-fw['f_net_o'])\n",
    "\t\t\t\t#print('y_i',y_i,'\\n')\n",
    "\t\t\t\t#print('f_net_o',fw['f_net_o'],'\\n')\n",
    "\t\t\t\t#print('error_o_k',error_o_k,'\\n')\n",
    "\t\t\t\t\n",
    "\t\t\t\ttotal_error = total_error + np.sum(error_o_k*error_o_k)\n",
    "\n",
    "\t\t\t\t#backpropagation / calculo das derivadas\n",
    "\t\t\t\tdelta_out = error_o_k*fw['df_net_o']\n",
    "\t\t\t\tdE2_dw_o = np.multiply(np.array([-2*delta_out]).T,np.concatenate((fw['f_net_h'],np.array([1]))))\n",
    "\n",
    "\t\t\t\tdelta_h = np.matmul(np.array([delta_out]),self.model['output_layer'][:,0:self.model['hidden_lenght']])\n",
    "\t\t\t\tdE2_dw_h = delta_h * (np.multiply(-2*fw['df_net_h'],np.array([np.concatenate((x_i,np.array([1])))]).T))\n",
    "\n",
    "\n",
    "\t\t\t\t# Atualização dos pesos\n",
    "\t\t\t\tself.model['output_layer'] = self.model['output_layer'] - eta*dE2_dw_o - alpha*self.dE2_dw_o_b\n",
    "\t\t\t\tif counter == 0:\n",
    "\t\t\t\t\tself.model['hidden_layer'] = self.model['hidden_layer'] - np.reshape(np.array([eta*dE2_dw_h]).T,(self.model['hidden_lenght'],x_i.size+1))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.model['hidden_layer'] = self.model['hidden_layer'] - np.reshape(np.array([eta*dE2_dw_h]).T,(self.model['hidden_lenght'],x_i.size+1)) - np.reshape(np.array([alpha*self.dE2_dw_h_b]).T,(self.model['hidden_lenght'],x_i.size+1))\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\t\tself.dE2_dw_o_b = dE2_dw_o\n",
    "\t\t\t\tself.dE2_dw_h_b = dE2_dw_h\n",
    "\n",
    "\t\t\t# Término da iteração do treinamento\n",
    "\t\t\ttotal_error = total_error/X.shape[0]\n",
    "\t\t\tcounter = counter+1\n",
    "\t\t\tif (counter % 100) == 0:\n",
    "\t\t\t\tprint(\"Iter:\",counter,\" Error:\",total_error)\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\tdef run(self,X,Y,task,size=8,eta=0.1,alpha=0.5,max_iter=500,train_size=0.7,threshold=0.000001):\n",
    "\t\tids = random.sample(range(0,X.shape[0]),np.floor(train_size*X.shape[0]).astype(np.int))\n",
    "\t\tids_left = diff(range(0,X.shape[0]),ids)\n",
    "\t\t#print('ids',ids,'\\n')\n",
    "\t\t#print('ids_left',ids_left,'\\n')\n",
    "\t\t# Training Set\n",
    "\t\ttrain_set = X[ids,:]\n",
    "\t\tY=np.array(Y)\n",
    "\t\ttrain_classes = Y[ids,:]\n",
    "\t\t#print('X=',train_set)\n",
    "\t\t#print('Y=',train_classes)\n",
    "\n",
    "\t\t# Test Set\n",
    "\t\ttest_set = X[ids_left,:]\n",
    "\t\ttest_classes = Y[ids_left,:]\n",
    "\t\t#print('X=',test_set)\n",
    "\t\t#print('Y=',test_classes)\n",
    "\n",
    "\t\tself.architecture(input_lenght=X.shape[1],hidden_lenght=size,output_lenght=Y.shape[1])\n",
    "\t\tprint('MLP architecture created\\nStarting Training')\n",
    "\t\tself.backpropagation(train_set,train_classes,eta=eta,alpha=alpha,max_error=threshold,max_iter=max_iter)\n",
    "\t\tprint('Neural Network Trained\\nStarting Testing')\n",
    "\t\t#print(mlp.forward(X)['f_net_o'])\n",
    "\n",
    "\t\tcorrect = 0\n",
    "\t\tsqerror = 0\n",
    "\t\tfor i in range(0,test_set.shape[0]):\n",
    "\t\t\tx_i = test_set[i]\n",
    "\t\t\ty_i = test_classes[i]\n",
    "\n",
    "\t\t\tif task == 'C':\n",
    "\t\t\t\ty_hat_i = np.round(self.forward(x_i)['f_net_o'])\n",
    "\t\t\tif task == 'R':\n",
    "\t\t\t\ty_hat_i = self.forward(x_i)['f_net_o']\n",
    "\t\t\t\n",
    "\t\t\terror = y_i - y_hat_i\n",
    "\t\t\tif (np.sum((error)**2) == 0):\n",
    "\t\t\t\tcorrect = correct + 1\n",
    "\t\t\tsqerror = sqerror + np.sum(error*error)\n",
    "\n",
    "\t\t\tpass\n",
    "\n",
    "\t\tprint('Neural Network Tested')\n",
    "\t\taccuracy = correct/test_set.shape[0]\n",
    "\t\tsqerror = sqerror/test_set.shape[0]\n",
    "\t\t\n",
    "\t\treturn {\n",
    "\t\t\t\"accuracy\": accuracy,\n",
    "\t\t\t\"error\": sqerror\n",
    "\t\t}\n",
    "\t#END OF MLP CLASS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the contents from a file and transforms in matrix\n",
    "def matrix(contents):\n",
    "\treturn [item.split(',') for item in contents.split('\\n')[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_ind(Y):\n",
    "\tunique_Y = set(Y)\n",
    "\t#print('unique_Y=',len(unique_Y),'\\n')\n",
    "\tsize = (Y.shape[0],len(unique_Y))\n",
    "\tres = np.zeros(size)\n",
    "\tfor i in range(0,Y.shape[0]):\n",
    "\t\tres[i][Y[i].astype(np.int)-1] = 1\n",
    "        #print('res=',res,'\\n')\n",
    "\treturn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(first, second):\n",
    "        second = set(second)\n",
    "        return [item for item in first if item not in second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_test(X,eta=0.1,alpha=0,max_iter=500,train_size=0.7):\n",
    "    X = np.array(X)\n",
    "    X = X.astype(np.float)\n",
    "    # Normalizing X\n",
    "    for i in range(X.shape[1]):\n",
    "        X[:,i] = (X[:,i] - np.amin(X[:,i])) / (np.amax(X[:,i]) - np.amin(X[:,i]))\n",
    "    print('\\nPreprocessing Digits Done')\n",
    "    mlp = MLP()\n",
    "    return mlp.run(X,Y,'C',eta=eta,alpha=alpha,max_iter=max_iter,train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits Choosen\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.010753365715189497\n",
      "Iter: 200  Error: 0.008235144425514958\n",
      "Iter: 300  Error: 0.006258691407054175\n",
      "Iter: 400  Error: 0.005632025945979545\n",
      "Iter: 500  Error: 0.005224673530933075\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.009903095285297684\n",
      "Iter: 200  Error: 0.006673418331046167\n",
      "Iter: 300  Error: 0.005988926301658284\n",
      "Iter: 400  Error: 0.005005120077168002\n",
      "Iter: 500  Error: 0.0048205278936345386\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.037472238922634356\n",
      "Iter: 200  Error: 0.03447468972855668\n",
      "Iter: 300  Error: 0.032653911802934026\n",
      "Iter: 400  Error: 0.03180445483062101\n",
      "Iter: 500  Error: 0.030861253427823112\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.01675966941216097\n",
      "Iter: 200  Error: 0.01243257270206803\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.01449075199645562\n",
      "Iter: 200  Error: 0.010078763684918413\n",
      "Iter: 300  Error: 0.008436001014242755\n",
      "Iter: 400  Error: 0.008056677773673327\n",
      "Iter: 500  Error: 0.007083973035563668\n",
      "Iter: 600  Error: 0.0069016660895098855\n",
      "Iter: 700  Error: 0.006795911162539833\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.0060642744319339545\n",
      "Iter: 200  Error: 0.003627830208993347\n",
      "Iter: 300  Error: 0.002166241039556954\n",
      "Iter: 400  Error: 0.0017514774333738596\n",
      "Iter: 500  Error: 0.001562317097014447\n",
      "Iter: 600  Error: 0.001444522419064765\n",
      "Iter: 700  Error: 0.0013627865141809432\n",
      "Iter: 800  Error: 0.0013024667969633828\n",
      "Iter: 900  Error: 0.0012560237539721545\n",
      "Iter: 1000  Error: 0.0012191032233996948\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.008371023605703227\n",
      "Iter: 200  Error: 0.005584486156308132\n",
      "Iter: 300  Error: 0.004803433703642735\n",
      "Iter: 400  Error: 0.004039924007570574\n",
      "Iter: 500  Error: 0.003521099702019144\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.009716553675832844\n",
      "Iter: 200  Error: 0.005205564242058853\n",
      "Iter: 300  Error: 0.004392908094932263\n",
      "Iter: 400  Error: 0.004050433934539413\n",
      "Iter: 500  Error: 0.0028533040311005268\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.017215625973893665\n",
      "Iter: 200  Error: 0.01298522588174264\n",
      "Iter: 300  Error: 0.011943976886693282\n",
      "Iter: 400  Error: 0.010419893857926403\n",
      "Iter: 500  Error: 0.010047633571079143\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.011226589734962456\n",
      "Iter: 200  Error: 0.009248972292273346\n",
      "Iter: 300  Error: 0.008777887828160255\n",
      "Iter: 400  Error: 0.008497448834935936\n",
      "Iter: 500  Error: 0.00774482294428802\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.008201105297628594\n",
      "Iter: 200  Error: 0.006487292396787525\n",
      "Iter: 300  Error: 0.003519451309574825\n",
      "Iter: 400  Error: 0.0032448413137931157\n",
      "Iter: 500  Error: 0.003108413728988609\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "\n",
      "Preprocessing Digits Done\n",
      "MLP architecture created\n",
      "Starting Training\n",
      "Iter: 100  Error: 0.032238826139295344\n",
      "Iter: 200  Error: 0.023784571535453512\n",
      "Iter: 300  Error: 0.02097098715641349\n",
      "Iter: 400  Error: 0.02013591440575234\n",
      "Iter: 500  Error: 0.020205120153701725\n",
      "Neural Network Trained\n",
      "Starting Testing\n",
      "Neural Network Tested\n",
      "+------------------+----------------+----------+-------------------+--------------------+\n",
      "| Number of Cycles | Learning Speed | Momentum | Training set size |      Accuracy      |\n",
      "+------------------+----------------+----------+-------------------+--------------------+\n",
      "|       500        |      0.1       |    0     |        0.7        | 0.801255230125523  |\n",
      "|       500        |      0.3       |    0     |        0.7        | 0.8389121338912134 |\n",
      "|       500        |      0.5       |    0     |        0.7        | 0.7761506276150628 |\n",
      "|       250        |      0.1       |    0     |        0.7        | 0.7824267782426778 |\n",
      "|       750        |      0.1       |    0     |        0.7        | 0.7782426778242678 |\n",
      "|       1000       |      0.1       |    0     |        0.7        | 0.7740585774058577 |\n",
      "|       500        |      0.1       |    0     |        0.5        | 0.7791718946047679 |\n",
      "|       500        |      0.1       |    0     |        0.6        | 0.7821316614420063 |\n",
      "|       500        |      0.1       |    0     |        0.9        |       0.7875       |\n",
      "|       500        |      0.1       |   0.1    |        0.7        | 0.7845188284518828 |\n",
      "|       500        |      0.1       |   0.3    |        0.7        | 0.801255230125523  |\n",
      "|       500        |      0.1       |   0.7    |        0.7        | 0.797071129707113  |\n",
      "+------------------+----------------+----------+-------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "print('Digits Choosen')\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Number of Cycles\",\"Learning Speed\",\"Momentum\",\"Training set size\",\"Accuracy\"]\n",
    "\n",
    "# Variation Learning Speed\n",
    "ret = digit_test(X,eta=0.1)\n",
    "table.add_row([500,0.1,0,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,eta=0.3)\n",
    "table.add_row([500,0.3,0,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,eta=0.5)\n",
    "table.add_row([500,0.5,0,0.7,ret['accuracy']])\n",
    "\n",
    "    # Variating Number of Cycles\n",
    "ret = digit_test(X,max_iter=250)\n",
    "table.add_row([250,0.1,0,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,max_iter=750)\n",
    "table.add_row([750,0.1,0,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,max_iter=1000)\n",
    "table.add_row([1000,0.1,0,0.7,ret['accuracy']])\n",
    "\n",
    "# Variating Training set size\n",
    "ret = digit_test(X,train_size=0.5)\n",
    "table.add_row([500,0.1,0,0.5,ret['accuracy']])\n",
    "ret = digit_test(X,train_size=0.6)\n",
    "table.add_row([500,0.1,0,0.6,ret['accuracy']])\n",
    "ret = digit_test(X,train_size=0.9)\n",
    "table.add_row([500,0.1,0,0.9,ret['accuracy']])\n",
    "\n",
    "# Variation Momentum\n",
    "ret = digit_test(X,alpha=0.1)\n",
    "table.add_row([500,0.1,0.1,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,alpha=0.3)\n",
    "table.add_row([500,0.1,0.3,0.7,ret['accuracy']])\n",
    "ret = digit_test(X,alpha=0.7)\n",
    "table.add_row([500,0.1,0.7,0.7,ret['accuracy']])\n",
    "\n",
    "# Printing Results\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
